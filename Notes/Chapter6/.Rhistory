install.packages("statsr")
chooseCRANmirror(graphics = F, ind = 1)
knitr::opts_chunk$set(echo = T)
library(statsr)
install.packages("mime")
chooseCRANmirror(graphics = F, ind = 1)
knitr::opts_chunk$set(echo = T)
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# standard error
se <- sqrt(phat * (1 - phat) / n)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phat - me
# upper confidence limit
ucl <- phat + me
lcl
ucl
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# hypothesized parameter
p <- 0.5
# standard deviation
stdev <- sqrt(p * (1 - p) / n)
# z-statistic
z <- (phat - p) / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard error
se <- sqrt(phat1 * (1 - phat1) / n1 + phat2 * (1 - phat2) / n2)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phatdif - me
# upper confidence limit
ucl <- phatdif + me
lcl
ucl
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value P(Z > z)
pv <- pnorm(z, lower.tail = F)
pv
# observed counts
obs <-  c(205, 26, 25, 19)
# expected proportions
est_props <-  c(0.72, 0.07, 0.12, 0.09)
# significance level
alpha <-  0.05
# expected counts
est <- sum(obs) * est_props
# chi-square statistic
chi <- sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 3
pv <- pchisq(chi, length(obs) - 1, lower.tail = F)
pv
# observed counts
obs <-  matrix(c(2, 23, 36, 71, 50, 37), nrow = 2, ncol = 3, byrow = T)
# significance level
alpha <-  0.05
# expected counts
rowtotals <-  apply(obs, 1, sum)
coltotals <-  apply(obs, 2, sum)
est <-  rowtotals %*% t(coltotals) / sum(obs)
# chi-square statistic
chi <-  sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 2
pv <-  pchisq(chi, (nrow(obs) - 1) * (ncol(obs) - 1), lower.tail = F)
pv
# The first list of the `pew_energe_2018` data set is the population.
pop <-  unlist(openintro::pew_energy_2018[1])
pop.prop <-  mean(pop == "favor_increase")
pop.prop
# Create a set of 10 million entries, where 88.9% are "yes", while 11.1% are "no".
pop.size <-  1e7
allentries <- c(rep("yes", pop.size * pop.prop), rep("no", pop.size * (1 - pop.prop)))
# Sample 1000 entries without replacement
sp.size = 1e3
sp = sample(allentries, sp.size, replace = F)
# sample proportion
sp.prop = mean(sp == "yes")
sp.prop
library(statsr)
inference(data = sp, statistic = "proportion", success = "yes", method = "theoretical", conf_level = 0.9, type = "ci")
str(sp)
sp = data.frame(sp)
str(sp)
names(sp)
names(sp) <- "x"
names(sp)
chooseCRANmirror(graphics = F, ind = 1)
knitr::opts_chunk$set(echo = T)
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# standard error
se <- sqrt(phat * (1 - phat) / n)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phat - me
# upper confidence limit
ucl <- phat + me
lcl
ucl
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# hypothesized parameter
p <- 0.5
# standard deviation
stdev <- sqrt(p * (1 - p) / n)
# z-statistic
z <- (phat - p) / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard error
se <- sqrt(phat1 * (1 - phat1) / n1 + phat2 * (1 - phat2) / n2)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phatdif - me
# upper confidence limit
ucl <- phatdif + me
lcl
ucl
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value P(Z > z)
pv <- pnorm(z, lower.tail = F)
pv
# observed counts
obs <-  c(205, 26, 25, 19)
# expected proportions
est_props <-  c(0.72, 0.07, 0.12, 0.09)
# significance level
alpha <-  0.05
# expected counts
est <- sum(obs) * est_props
# chi-square statistic
chi <- sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 3
pv <- pchisq(chi, length(obs) - 1, lower.tail = F)
pv
# observed counts
obs <-  matrix(c(2, 23, 36, 71, 50, 37), nrow = 2, ncol = 3, byrow = T)
# significance level
alpha <-  0.05
# expected counts
rowtotals <-  apply(obs, 1, sum)
coltotals <-  apply(obs, 2, sum)
est <-  rowtotals %*% t(coltotals) / sum(obs)
# chi-square statistic
chi <-  sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 2
pv <-  pchisq(chi, (nrow(obs) - 1) * (ncol(obs) - 1), lower.tail = F)
pv
# The first list of the `pew_energe_2018` data set is the population.
pop <-  unlist(openintro::pew_energy_2018[1])
pop.prop <-  mean(pop == "favor_increase")
pop.prop
# Create a set of 10 million entries, where 88.9% are "yes", while 11.1% are "no".
pop.size <-  1e7
allentries <- c(rep("yes", pop.size * pop.prop), rep("no", pop.size * (1 - pop.prop)))
# Sample 1000 entries without replacement
sp.size = 1e3
sp = sample(allentries, sp.size, replace = F)
# sample proportion
sp.prop = mean(sp == "yes")
sp.prop
library(statsr)
# convert sp to a dataframe
sp = data.frame(sp)
names(sp) = "x"
inference(y = "x", data = sp, statistic = "proportion", success = "yes", method = "theoretical", conf_level = 0.9, type = "ci")
nrow(sp)
head(sp)
inference(y = "x", data = sp, statistic = "proportion", success = "yes", method = "simulation", type = "ht", sig_level = 0.05, null = 0.88, alternative = "twosided")
inference(y = x, data = sp, statistic = "proportion", success = "yes", method = "theoretical", conf_level = 0.9, type = "ci")
chooseCRANmirror(graphics = F, ind = 1)
knitr::opts_chunk$set(echo = T)
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# standard error
se <- sqrt(phat * (1 - phat) / n)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phat - me
# upper confidence limit
ucl <- phat + me
lcl
ucl
# sample size
n <- 100
# sample proportion
phat <- 45/100
# significance level
alpha <- 0.05
# hypothesized parameter
p <- 0.5
# standard deviation
stdev <- sqrt(p * (1 - p) / n)
# z-statistic
z <- (phat - p) / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard error
se <- sqrt(phat1 * (1 - phat1) / n1 + phat2 * (1 - phat2) / n2)
# margin of error
me <- qnorm(alpha / 2, lower.tail = F) * se
# lower confidence limit
lcl <- phatdif - me
# upper confidence limit
ucl <- phatdif + me
lcl
ucl
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value
pv <- 2 * pnorm(abs(z), lower.tail = F)
pv
# sample sizes
n1 <- 800
n2 <- 1000
# sample proportions
phat1 <- 460 / 800
phat2 <- 520 / 1000
phatpooled <- (460 + 520) / (n1 + n2)
# significance level
alpha <- 0.05
# sample difference
phatdif <- phat1 - phat2
# standard deviation
stdev <- sqrt(phatpooled * (1 - phatpooled) / n1 + phatpooled * (1 - phatpooled) / n2)
# z-statistic; note the hypothesized parameter is zero
z <- phatdif / stdev
# p-value P(Z > z)
pv <- pnorm(z, lower.tail = F)
pv
# observed counts
obs <-  c(205, 26, 25, 19)
# expected proportions
est_props <-  c(0.72, 0.07, 0.12, 0.09)
# significance level
alpha <-  0.05
# expected counts
est <- sum(obs) * est_props
# chi-square statistic
chi <- sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 3
pv <- pchisq(chi, length(obs) - 1, lower.tail = F)
pv
# observed counts
obs <-  matrix(c(2, 23, 36, 71, 50, 37), nrow = 2, ncol = 3, byrow = T)
# significance level
alpha <-  0.05
# expected counts
rowtotals <-  apply(obs, 1, sum)
coltotals <-  apply(obs, 2, sum)
est <-  rowtotals %*% t(coltotals) / sum(obs)
# chi-square statistic
chi <-  sum((obs - est) ** 2 / est)
# p-value P(X^2 > chi); df = 2
pv <-  pchisq(chi, (nrow(obs) - 1) * (ncol(obs) - 1), lower.tail = F)
pv
# The first list of the `pew_energe_2018` data set is the population.
pop <-  unlist(openintro::pew_energy_2018[1])
pop.prop <-  mean(pop == "favor_increase")
pop.prop
# Create a set of 10 million entries, where 88.9% are "yes", while 11.1% are "no".
pop.size <-  1e7
allentries <- c(rep("yes", pop.size * pop.prop), rep("no", pop.size * (1 - pop.prop)))
# Sample 1000 entries without replacement
sp.size = 1e3
sp = sample(allentries, sp.size, replace = F)
# sample proportion
sp.prop = mean(sp == "yes")
sp.prop
library(statsr)
# convert sp to a dataframe
sp = data.frame(sp)
names(sp) = "x"
inference(y = x, data = sp, statistic = "proportion", success = "yes", method = "theoretical", conf_level = 0.9, type = "ci")
inference(y = x, data = sp, statistic = "proportion", success = "yes", method = "simulation", type = "ht", sig_level = 0.05, null = 0.88, alternative = "twosided")
inference(y = x, data = sp, statistic = "proportion", success = "yes", method = "simulation", type = "ht", sig_level = 0.05, null = 0.88, alternative = "greater")
